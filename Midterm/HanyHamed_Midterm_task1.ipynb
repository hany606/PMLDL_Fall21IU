{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HanyHamed_Midterm_task1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJO9FYt89gEk"
      },
      "source": [
        "## PMLDL Midterm - Fall 21\n",
        "## **Task 1**\n",
        "\n",
        "You are given a working code that performs a classification task on a given dataset. The data contains 10 classes (airplne, automobile, bird, cat, dog deer, frog, horse, ship, truck).\n",
        "\n",
        "The model produces unsatisfactory results which can be improved. Your task will be to improve the results by making the necessary changes to the code.\n",
        "\n",
        "Link to dataset : https://drive.google.com/file/d/1vOQeC2H_9qSYXRDdtKf59QEkjUlBRiGj/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhEn17aRa4dO"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "import os \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader , Dataset\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.utils"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV1lggOQZti0",
        "outputId": "292b618d-6204-455e-b466-485d147df759"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rqturVaaNn7",
        "outputId": "2e9d362a-5c51-4788-99df-32feafca3efa"
      },
      "source": [
        "!unzip 'drive/MyDrive/dataset-1.zip' "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/dataset-1.zip\n",
            "replace dataset-1/class_names.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fetujjC0buC3",
        "outputId": "5d5c4512-9031-4c16-cd0d-3012db634d23"
      },
      "source": [
        "num_batches = 512\n",
        "random_state = 43\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "def read_images(path_to_data):\n",
        "    with open(path_to_data, 'rb') as f:\n",
        "        everything = np.fromfile(f, dtype=np.uint8)\n",
        "        images = np.reshape(everything, (-1, 3, 96, 96))\n",
        "        images = np.transpose(images, (0, 3, 2, 1))\n",
        "        return images\n",
        "\n",
        "def read_labels(path_to_labels):\n",
        "    with open(path_to_labels, 'rb') as f:\n",
        "        labels = np.fromfile(f, dtype=np.uint8)\n",
        "        return labels\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels,transforms=None):\n",
        "        self.labels = labels\n",
        "        self.images = images \n",
        "        self.transform = transforms\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.labels[idx] - 1\n",
        "        data = self.images[idx]\n",
        "        if self.transform is not None:\n",
        "            return (self.transform(data),label)\n",
        "        else:\n",
        "            return (data,label)\n",
        "\n",
        "X_train = read_images('dataset-1/train_X.bin')  # Changed the path as it was not working (original: stl10_binary)\n",
        "X_test = read_images('dataset-1/test_X.bin')\n",
        "y_train = read_labels('dataset-1/train_y.bin')\n",
        "y_test = read_labels('dataset-1/test_y.bin')\n",
        "\n",
        "\n",
        "train_data = CustomDataset(X_train,y_train,train_transform)\n",
        "train_loader = DataLoader(train_data,batch_size=num_batches,shuffle=True)\n",
        "\n",
        "test_data =   CustomDataset(X_test,y_test,test_transform)\n",
        "test_loader = DataLoader(test_data,batch_size=num_batches,shuffle=True)\n",
        "\n",
        "torch.manual_seed(random_state)\n",
        "\n",
        "print(\"Train data %.d  Test data %.d \"%(len(train_loader.dataset),len(test_loader.dataset)))\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data 5000  Test data 8000 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jGPcr97gMm3"
      },
      "source": [
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "NB_CLASS = 10\n",
        "class CNN_model(nn.Module):\n",
        "    def __init__(self,nb_class):\n",
        "        super(CNN_model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 5)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(12800, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 512)\n",
        "        self.fc3 = nn.Linear(512, 128)\n",
        "        self.fc4 = nn.Linear(128, nb_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool(F.relu(self.bn1(x)))\n",
        "        # x = self.dropout(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool(F.relu(self.bn2(x)))\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.pool(F.relu(self.bn3(x)))\n",
        "        # x = self.dropout(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        # print(x.shape)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = (self.fc4(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "model = CNN_model(NB_CLASS)\n",
        "model = model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.002)\n",
        "scheduler = None\n",
        "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv7S9b4LbxZn"
      },
      "source": [
        "def calculate_accuracy(y_pred, y):\n",
        "    top_pred = y_pred.argmax(1, keepdim = True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc\n",
        "\n",
        "def train(model,train_loader,loss_fn,optimizer,scheduler,device):\n",
        "    accuracy = 0\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    model.train()\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data\n",
        "        images,labels = inputs.to(device) , labels.to(device) \n",
        "        optimizer.zero_grad()\n",
        "        outputs= model(images)\n",
        "        loss = loss_fn(outputs, labels.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()* images.size(0)\n",
        "        total += images.size(0)\n",
        "        preds = torch.argmax(outputs.data, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        if i % 300 == 0:   \n",
        "            print('[%d, %5d] Acc: %.3f loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, correct/total, running_loss /total))\n",
        "            running_loss = 0.0\n",
        "        # scheduler.step(loss/total)\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (images, labels) in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            output = model(images)\n",
        "            loss = criterion(output, labels)\n",
        "            acc = calculate_accuracy(output, labels)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    \n",
        "    print(\"Epoch %d Test Accuracy %.3f\" % (epoch, epoch_acc/ len(loader)))"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9mwO7dcbyT3",
        "outputId": "c2639905-2519-436c-8fce-147af2e9ae64"
      },
      "source": [
        "for epoch in range(70):\n",
        "    train(model,train_loader,loss_fn,optimizer,scheduler,device)\n",
        "    evaluate(model,test_loader,loss_fn,device)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,     1] Acc: 0.100 loss: 2.304\n",
            "Epoch 0 Test Accuracy 0.123\n",
            "[2,     1] Acc: 0.131 loss: 2.257\n",
            "Epoch 1 Test Accuracy 0.197\n",
            "[3,     1] Acc: 0.230 loss: 2.105\n",
            "Epoch 2 Test Accuracy 0.296\n",
            "[4,     1] Acc: 0.252 loss: 1.957\n",
            "Epoch 3 Test Accuracy 0.281\n",
            "[5,     1] Acc: 0.322 loss: 1.789\n",
            "Epoch 4 Test Accuracy 0.357\n",
            "[6,     1] Acc: 0.318 loss: 1.718\n",
            "Epoch 5 Test Accuracy 0.384\n",
            "[7,     1] Acc: 0.383 loss: 1.640\n",
            "Epoch 6 Test Accuracy 0.394\n",
            "[8,     1] Acc: 0.383 loss: 1.599\n",
            "Epoch 7 Test Accuracy 0.429\n",
            "[9,     1] Acc: 0.445 loss: 1.460\n",
            "Epoch 8 Test Accuracy 0.436\n",
            "[10,     1] Acc: 0.457 loss: 1.444\n",
            "Epoch 9 Test Accuracy 0.441\n",
            "[11,     1] Acc: 0.500 loss: 1.397\n",
            "Epoch 10 Test Accuracy 0.479\n",
            "[12,     1] Acc: 0.445 loss: 1.349\n",
            "Epoch 11 Test Accuracy 0.486\n",
            "[13,     1] Acc: 0.518 loss: 1.265\n",
            "Epoch 12 Test Accuracy 0.510\n",
            "[14,     1] Acc: 0.541 loss: 1.133\n",
            "Epoch 13 Test Accuracy 0.512\n",
            "[15,     1] Acc: 0.600 loss: 1.109\n",
            "Epoch 14 Test Accuracy 0.515\n",
            "[16,     1] Acc: 0.525 loss: 1.190\n",
            "Epoch 15 Test Accuracy 0.535\n",
            "[17,     1] Acc: 0.578 loss: 1.070\n",
            "Epoch 16 Test Accuracy 0.544\n",
            "[18,     1] Acc: 0.600 loss: 1.036\n",
            "Epoch 17 Test Accuracy 0.526\n",
            "[19,     1] Acc: 0.605 loss: 1.011\n",
            "Epoch 18 Test Accuracy 0.550\n",
            "[20,     1] Acc: 0.650 loss: 0.959\n",
            "Epoch 19 Test Accuracy 0.559\n",
            "[21,     1] Acc: 0.705 loss: 0.833\n",
            "Epoch 20 Test Accuracy 0.572\n",
            "[22,     1] Acc: 0.723 loss: 0.823\n",
            "Epoch 21 Test Accuracy 0.571\n",
            "[23,     1] Acc: 0.719 loss: 0.798\n",
            "Epoch 22 Test Accuracy 0.535\n",
            "[24,     1] Acc: 0.764 loss: 0.722\n",
            "Epoch 23 Test Accuracy 0.590\n",
            "[25,     1] Acc: 0.727 loss: 0.709\n",
            "Epoch 24 Test Accuracy 0.591\n",
            "[26,     1] Acc: 0.756 loss: 0.668\n",
            "Epoch 25 Test Accuracy 0.593\n",
            "[27,     1] Acc: 0.771 loss: 0.652\n",
            "Epoch 26 Test Accuracy 0.582\n",
            "[28,     1] Acc: 0.795 loss: 0.579\n",
            "Epoch 27 Test Accuracy 0.599\n",
            "[29,     1] Acc: 0.770 loss: 0.584\n",
            "Epoch 28 Test Accuracy 0.613\n",
            "[30,     1] Acc: 0.812 loss: 0.509\n",
            "Epoch 29 Test Accuracy 0.602\n",
            "[31,     1] Acc: 0.816 loss: 0.512\n",
            "Epoch 30 Test Accuracy 0.602\n",
            "[32,     1] Acc: 0.857 loss: 0.407\n",
            "Epoch 31 Test Accuracy 0.616\n",
            "[33,     1] Acc: 0.863 loss: 0.382\n",
            "Epoch 32 Test Accuracy 0.617\n",
            "[34,     1] Acc: 0.840 loss: 0.448\n",
            "Epoch 33 Test Accuracy 0.610\n",
            "[35,     1] Acc: 0.863 loss: 0.375\n",
            "Epoch 34 Test Accuracy 0.609\n",
            "[36,     1] Acc: 0.854 loss: 0.387\n",
            "Epoch 35 Test Accuracy 0.619\n",
            "[37,     1] Acc: 0.850 loss: 0.404\n",
            "Epoch 36 Test Accuracy 0.618\n",
            "[38,     1] Acc: 0.885 loss: 0.324\n",
            "Epoch 37 Test Accuracy 0.618\n",
            "[39,     1] Acc: 0.910 loss: 0.279\n",
            "Epoch 38 Test Accuracy 0.621\n",
            "[40,     1] Acc: 0.889 loss: 0.293\n",
            "Epoch 39 Test Accuracy 0.616\n",
            "[41,     1] Acc: 0.918 loss: 0.249\n",
            "Epoch 40 Test Accuracy 0.618\n",
            "[42,     1] Acc: 0.896 loss: 0.283\n",
            "Epoch 41 Test Accuracy 0.618\n",
            "[43,     1] Acc: 0.941 loss: 0.205\n",
            "Epoch 42 Test Accuracy 0.597\n",
            "[44,     1] Acc: 0.914 loss: 0.222\n",
            "Epoch 43 Test Accuracy 0.605\n",
            "[45,     1] Acc: 0.924 loss: 0.204\n",
            "Epoch 44 Test Accuracy 0.616\n",
            "[46,     1] Acc: 0.926 loss: 0.202\n",
            "Epoch 45 Test Accuracy 0.609\n",
            "[47,     1] Acc: 0.924 loss: 0.234\n",
            "Epoch 46 Test Accuracy 0.609\n",
            "[48,     1] Acc: 0.918 loss: 0.247\n",
            "Epoch 47 Test Accuracy 0.606\n",
            "[49,     1] Acc: 0.928 loss: 0.197\n",
            "Epoch 48 Test Accuracy 0.612\n",
            "[50,     1] Acc: 0.938 loss: 0.209\n",
            "Epoch 49 Test Accuracy 0.623\n",
            "[51,     1] Acc: 0.939 loss: 0.166\n",
            "Epoch 50 Test Accuracy 0.622\n",
            "[52,     1] Acc: 0.943 loss: 0.179\n",
            "Epoch 51 Test Accuracy 0.616\n",
            "[53,     1] Acc: 0.936 loss: 0.159\n",
            "Epoch 52 Test Accuracy 0.632\n",
            "[54,     1] Acc: 0.959 loss: 0.136\n",
            "Epoch 53 Test Accuracy 0.619\n",
            "[55,     1] Acc: 0.951 loss: 0.143\n",
            "Epoch 54 Test Accuracy 0.628\n",
            "[56,     1] Acc: 0.961 loss: 0.118\n",
            "Epoch 55 Test Accuracy 0.630\n",
            "[57,     1] Acc: 0.961 loss: 0.130\n",
            "Epoch 56 Test Accuracy 0.618\n",
            "[58,     1] Acc: 0.959 loss: 0.144\n",
            "Epoch 57 Test Accuracy 0.616\n",
            "[59,     1] Acc: 0.961 loss: 0.124\n",
            "Epoch 58 Test Accuracy 0.623\n",
            "[60,     1] Acc: 0.963 loss: 0.142\n",
            "Epoch 59 Test Accuracy 0.615\n",
            "[61,     1] Acc: 0.969 loss: 0.108\n",
            "Epoch 60 Test Accuracy 0.631\n",
            "[62,     1] Acc: 0.967 loss: 0.093\n",
            "Epoch 61 Test Accuracy 0.616\n",
            "[63,     1] Acc: 0.955 loss: 0.141\n",
            "Epoch 62 Test Accuracy 0.615\n",
            "[64,     1] Acc: 0.965 loss: 0.098\n",
            "Epoch 63 Test Accuracy 0.627\n",
            "[65,     1] Acc: 0.973 loss: 0.083\n",
            "Epoch 64 Test Accuracy 0.624\n",
            "[66,     1] Acc: 0.980 loss: 0.063\n",
            "Epoch 65 Test Accuracy 0.628\n",
            "[67,     1] Acc: 0.967 loss: 0.085\n",
            "Epoch 66 Test Accuracy 0.623\n",
            "[68,     1] Acc: 0.980 loss: 0.063\n",
            "Epoch 67 Test Accuracy 0.631\n",
            "[69,     1] Acc: 0.975 loss: 0.083\n",
            "Epoch 68 Test Accuracy 0.621\n",
            "[70,     1] Acc: 0.980 loss: 0.080\n",
            "Epoch 69 Test Accuracy 0.620\n"
          ]
        }
      ]
    }
  ]
}