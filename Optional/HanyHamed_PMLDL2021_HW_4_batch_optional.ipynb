{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "HanyHamed_PMLDL2021_HW_4_batch_optional.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CZVi9MUj_Dzj"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hany606/PMLDL_Fall21IU/blob/main/Optional/HanyHamed_PMLDL2021_HW_4_batch_optional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL5wcxMPCK_0"
      },
      "source": [
        "# Hany Hamed Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCrCqMw1_DzS"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsuB8Nid_DzV"
      },
      "source": [
        "PML&DL Homework (optional)\n",
        "=============================\n",
        "Based on the Tutorial: https://docs.dgl.ai/en/0.4.x/tutorials/basics/4_batch.html \n",
        "\n",
        "Instructions for the assignment are given in tags: [PMLDL] ... [/PMLDL]\n",
        "\n",
        "Graph classification is an important problem\n",
        "with applications across many fields, such as bioinformatics, chemoinformatics, social\n",
        "network analysis, urban computing, and cybersecurity. Applying graph neural\n",
        "networks to this problem has been a popular approach recently. This can be seen in the following reserach references: \n",
        "`Ying et al., 2018 <https://arxiv.org/abs/1806.08804>`_,\n",
        "`Cangea et al., 2018 <https://arxiv.org/abs/1811.01287>`_,\n",
        "`Knyazev et al., 2018 <https://arxiv.org/abs/1811.09595>`_,\n",
        "`Bianchi et al., 2019 <https://arxiv.org/abs/1901.01343>`_,\n",
        "`Liao et al., 2019 <https://arxiv.org/abs/1901.01484>`_,\n",
        "`Gao et al., 2019 <https://openreview.net/forum?id=HJePRoAct7>`_).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBOFmi4C_DzX"
      },
      "source": [
        "Simple graph classification task\n",
        "--------------------------------\n",
        "In this tutorial, you learn how to perform batched graph classification\n",
        "with DGL. The example task objective is to classify eight types of topologies shown here.\n",
        "\n",
        "![](https://data.dgl.ai/tutorial/batch/dataset_overview.png)\n",
        "\n",
        "    :align: center\n",
        "\n",
        "Implement a synthetic dataset :class:`data.MiniGCDataset` in DGL. The dataset has eight \n",
        "different types of graphs and each class has the same number of graph samples.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM1WodOo_DzZ",
        "outputId": "54a85037-64e3-42eb-c9ac-6696fb8df34b"
      },
      "source": [
        "pip install dgl-cu113 -f https://data.dgl.ai/wheels/repo.html\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Collecting dgl-cu113\n",
            "  Downloading https://data.dgl.ai/wheels/dgl_cu113-0.7.2-cp37-cp37m-manylinux1_x86_64.whl (152.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 152.9 MB 37 kB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (2.6.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu113) (1.19.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu113) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu113) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu113) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu113) (2.10)\n",
            "Installing collected packages: dgl-cu113\n",
            "Successfully installed dgl-cu113-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjv-O-a1_Dza"
      },
      "source": [
        "import dgl\n",
        "from dgl.data import MiniGCDataset\n",
        "import numpy as np\n",
        "import dgl.contrib.sampling.randomwalk\n",
        "\n",
        "# Sources to check: \n",
        "# https://towardsdatascience.com/node2vec-embeddings-for-graph-data-32a866340fef\n",
        "# http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\n",
        "# https://github.com/eliorc/Medium/blob/master/Nod2Vec-FIFA17-Example.ipynb\n",
        "# https://towardsdatascience.com/complete-guide-to-understanding-node2vec-algorithm-4e9a35e5d147\n",
        "# https://stellargraph.readthedocs.io/en/stable/demos/node-classification/node2vec-node-classification.html\n",
        "# https://stellargraph.readthedocs.io/en/stable/demos/embeddings/node2vec-embeddings.html\n",
        "\n",
        "'''\n",
        "[PMLDL]\n",
        "Check the MiniGCDataset source code and implement a class that generated a vector of features for each node (e.g. using node2vec).\n",
        "So, result would be a YourNameItGCDataset class. \n",
        "[/PMLDL]\n",
        "''' \n",
        "\n",
        "class HanyHamedGCDataset(MiniGCDataset):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        # self.dimensions = kwargs.get(\"dimensions\", 50) \n",
        "        self.walk_length = kwargs.get(\"walk_length\", 50) \n",
        "        self.num_walks = kwargs.get(\"num_walks\", 1) \n",
        "\n",
        "        kwargs.pop(\"walk_length\", None)\n",
        "        kwargs.pop(\"num_walks\", None)\n",
        "\n",
        "        super(HanyHamedGCDataset, self).__init__(*args, **kwargs)\n",
        "        self. walk_length -= 1\n",
        "        # self.model_features = self.gen_feature_vector(self.graphs, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, window=window, min_count=min_count)\n",
        "        # self.edges_embs = HadamardEmbedder(keyed_vectors=self.model_features.wv)\n",
        "\n",
        "    def gen_feature_vector(self, g, dimensions, walk_length, num_walks, window, min_count):\n",
        "        # Compute the feature vector\n",
        "        # Source: https://towardsdatascience.com/node2vec-embeddings-for-graph-data-32a866340fef\n",
        "        g_networkx = dgl.batch(g).to_networkx()\n",
        "        node2vec = Node2Vec(g_networkx, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks)\n",
        "        model = node2vec.fit(window=window, min_count=min_count)\n",
        "        # print(dgl.batch(g).nodes())\n",
        "        # Do node2vec using word2vec (Source: https://stellargraph.readthedocs.io/en/stable/demos/node-classification/node2vec-node-classification.html) \n",
        "        # nodes = dgl.batch(g).nodes()\n",
        "        # dgl.sampling.random_walk(g.nodes(), [0, 1, 2, 0], length=walk_length)\n",
        "        # str_walks = [[str(n) for n in walk] for walk in walks]\n",
        "        # from gensim.models import Word2Vec\n",
        "        # model = Word2Vec(str_walks, size=128, window=5, min_count=0, sg=1, workers=2, iter=1)\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Source: https://github.com/eliorc/Medium/blob/master/Nod2Vec-FIFA17-Example.ipynb\n",
        "        # model_features = self.gen_feature_vector(self.graphs[idx], dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, window=window, min_count=min_count)\n",
        "        # print(self.graphs[idx])\n",
        "        # nodes = [x for x in model.wv.vocab if len(x) > 3 and x not in clubs]\n",
        "        # embeddings = np.array(self.model_features.wv[self.graphs[idx].nodes()])\n",
        "        # Source: https://github.com/eliorc/node2vec\n",
        "        # self.edges_embs = HadamardEmbedder(keyed_vectors=self.model_features.wv)\n",
        "        # print(edges_embs[('1', '2')])\n",
        "        # print(self.graphs[idx].edges())\n",
        "        # embeddings = self.edges_embs[self.graphs[idx].edges()]\n",
        "        # embeddings = self.model_features.wv[self.graphs[idx].nodes()]\n",
        "        # embeddings = dgl.sampling.node2vec_random_walk(self.graphs[idx], np.random.randint(len(self.graphs[idx].nodes()), size=len(self.graphs[idx].in_degrees())), 1, 1, walk_length=self.walk_length)\n",
        "        embeddings = dgl.sampling.node2vec_random_walk(self.graphs[idx], np.random.randint(len(self.graphs[idx].nodes()), size=self.num_walks), 1, 1, walk_length=self.walk_length)\n",
        "        return self.graphs[idx], embeddings, self.labels[idx]\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "# A dataset with 80 samples, each graph is\n",
        "# of size [10, 20]\n",
        "# dataset = MiniGCDataset(80, 10, 20)\n",
        "# graph, label = dataset[0]\n",
        "\n",
        "'''\n",
        "[PMLDL]\n",
        "\n",
        "Here YourNameItGCDataset dataset[0] should return a three elements: \n",
        "graph, node_features, label = dataset[0]\n",
        "node_features stores all node features of the graph\n",
        "\n",
        "[/PMLDL]\n",
        "''' \n",
        "dataset = HanyHamedGCDataset(80, 10, 20)\n",
        "graph, node_features, label = dataset[0]\n",
        "\n"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EABhXg_c_Dzc"
      },
      "source": [
        "Form a graph mini-batch\n",
        "-----------------------\n",
        "To train neural networks efficiently, a common practice is to batch\n",
        "multiple samples together to form a mini-batch. Batching fixed-shaped tensor\n",
        "inputs is common. For example, batching two images of size 28 x 28\n",
        "gives a tensor of shape 2 x 28 x 28. By contrast, batching graph inputs\n",
        "has two challenges:\n",
        "\n",
        "* Graphs are sparse.\n",
        "* Graphs can have various length. For example, number of nodes and edges.\n",
        "\n",
        "To address this, DGL provides a :func:`dgl.batch` API. It leverages the idea that\n",
        "a batch of graphs can be viewed as a large graph that has many disjointed \n",
        "connected components. Below is a visualization that gives the general idea.\n",
        "\n",
        "![](https://data.dgl.ai/tutorial/batch/batch.png)\n",
        "\n",
        "    :width: 400pt\n",
        "    :align: center\n",
        "\n",
        "Define the following ``collate`` function to form a mini-batch from a given\n",
        "list of graph and label pairs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQTQ8dfS_Dzd"
      },
      "source": [
        "import dgl\n",
        "import torch\n",
        "\n",
        "def collate(samples):\n",
        "    # The input `samples` is a list of pairs\n",
        "    #  (graph, label).\n",
        "    graphs, labels = map(list, zip(*samples))\n",
        "    batched_graph = dgl.batch(graphs)\n",
        "    return batched_graph, torch.tensor(labels)\n",
        "\n",
        "'''\n",
        "[PMLDL]\n",
        "\n",
        "Here you need to implement a new version of the collate(...) function.\n",
        "New version should collate (stack) the graph, features and labels in a mini-batch.\n",
        "\n",
        "[/PMLDL]\n",
        "''' \n",
        "\n",
        "def new_collate(samples):\n",
        "    graphs, node_features, labels = map(list, zip(*samples))\n",
        "    node_features = torch.cat(node_features, dim=0)\n",
        "    batched_graph = dgl.batch(graphs)\n",
        "    return batched_graph, node_features, torch.tensor(labels)\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6DN6gUu_Dzd"
      },
      "source": [
        "The return type of :func:`dgl.batch` is still a graph. In the same way, \n",
        "a batch of tensors is still a tensor. This means that any code that works\n",
        "for one graph immediately works for a batch of graphs. More importantly,\n",
        "because DGL processes messages on all nodes and edges in parallel, this greatly\n",
        "improves efficiency.\n",
        "\n",
        "Graph classifier\n",
        "----------------\n",
        "Graph classification proceeds as follows.\n",
        "\n",
        "![](https://data.dgl.ai/tutorial/batch/graph_classifier.png)\n",
        "\n",
        "\n",
        "From a batch of graphs, perform message passing and graph convolution\n",
        "for nodes to communicate with others. After message passing, compute a\n",
        "tensor for graph representation from node (and edge) attributes. This step might \n",
        "be called readout or aggregation. Finally, the graph \n",
        "representations are fed into a classifier $g$ to predict the graph labels.\n",
        "\n",
        "Graph convolution layer can be found in the ``dgl.nn.<backend>`` submodule.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p16eMTmm_Dze"
      },
      "source": [
        "from dgl.nn.pytorch import GraphConv"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUwRhUKT_Dzf"
      },
      "source": [
        "Readout and classification\n",
        "--------------------------\n",
        "For this demonstration, consider initial node features to be their degrees.\n",
        "After two rounds of graph convolution, perform a graph readout by averaging\n",
        "over all node features for each graph in the batch.\n",
        "\n",
        "\\begin{align}h_g=\\frac{1}{|\\mathcal{V}|}\\sum_{v\\in\\mathcal{V}}h_{v}\\end{align}\n",
        "\n",
        "In DGL, :func:`dgl.mean_nodes` handles this task for a batch of\n",
        "graphs with variable size. You then feed the graph representations into a\n",
        "classifier with one linear layer to obtain pre-softmax logits.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TocZJGji_Dzg"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, n_classes):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.conv1 = GraphConv(in_dim, hidden_dim)#, norm=\"none\")\n",
        "        self.conv2 = GraphConv(hidden_dim, hidden_dim)\n",
        "        self.classify = nn.Linear(hidden_dim, n_classes)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        '''\n",
        "        [PMLDL]\n",
        "        This call: h = g.in_degrees().view(-1, 1).float()\n",
        "        feeds nodes degees list into input of the GCN (so, in_dim == 1).\n",
        "\n",
        "        Here you need to change the code to feed features of nodes into input layer.\n",
        "        Thus, in_dim will be the dimension of a feature-vector (say, 50). \n",
        "        In the lecture slides such vector for a node v was called x_v\n",
        "\n",
        "        [/PMLDL]\n",
        "        ''' \n",
        "\n",
        "        '''\n",
        "        Reply: \n",
        "            From GraphConv -> def forward(self, graph, feat, weight=None, edge_weight=None):\n",
        "            However, when I pass the features, I got the following error\n",
        "            \"RuntimeError: The size of tensor a (32) must match the size of tensor b (443) at non-singleton dimension 0\"\n",
        "\n",
        "            Also, when specifying the in_dim as 50 I got the following error which seems that the matrix of weights should be \n",
        "            mat1 and mat2 shapes cannot be multiplied (418x1 and 50x256)\n",
        "\n",
        "            So, it is some part of the code, the matrix dimension is related to the number of the in-degree of the nodes in the graph\n",
        "\n",
        "            Thus, I have changed the layers to normal FC to feed forward the feature vector\n",
        "        '''\n",
        "        # This works somehow for having GraphConv\n",
        "        # But the in_dim should be 1 not 50\n",
        "        # h = features.view(-1, 1)[:len(g.in_degrees())]\n",
        "        # # Perform graph convolution and activation function.\n",
        "        # h = F.relu(self.conv1(g, h))\n",
        "        # h = F.relu(self.conv2(g, h))\n",
        "        # g.ndata['h'] = h\n",
        "        # # Calculate graph representation by averaging all the node representations.\n",
        "        # hg = dgl.mean_nodes(g, 'h')\n",
        "        # return self.classify(hg)\n",
        "\n",
        "        h = F.relu(self.fc1(features.float()))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        return self.classify(h)\n"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgnAqk4K_Dzg"
      },
      "source": [
        "Setup and training\n",
        "------------------\n",
        "Create a synthetic dataset of $400$ graphs with $10$ ~\n",
        "$20$ nodes. $320$ graphs constitute a training set and\n",
        "$80$ graphs constitute a test set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "774QvzgY_Dzh",
        "outputId": "d6d156d9-46e1-4cdd-8a5c-07d8aed677ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create training and test sets.\n",
        "'''\n",
        "[PMLDL]\n",
        "\n",
        "Here calls to the YourNameItGCDataset class\n",
        "\n",
        "[/PMLDL]\n",
        "''' \n",
        "# trainset = MiniGCDataset(320, 10, 20)\n",
        "# testset = MiniGCDataset(80, 10, 20)\n",
        "\n",
        "trainset = HanyHamedGCDataset(320, 10, 20, walk_length=50)\n",
        "testset = HanyHamedGCDataset(80, 10, 20, walk_length=50)\n",
        "\n",
        "\n",
        "# Use PyTorch's DataLoader and the collate function\n",
        "# defined before.\n",
        "'''\n",
        "[PMLDL]\n",
        "\n",
        "Here pass new version of collate()\n",
        "\n",
        "[/PMLDL]\n",
        "''' \n",
        "# data_loader = DataLoader(trainset, batch_size=32, shuffle=True,\n",
        "#                          collate_fn=collate)\n",
        "\n",
        "data_loader = DataLoader(trainset, batch_size=32, shuffle=True,\n",
        "                         collate_fn=new_collate)\n",
        "\n",
        "\n",
        "# Create model\n",
        "'''\n",
        "[PMLDL]\n",
        "\n",
        "Here pass new dimension of input (say, 50) as the first parameter.\n",
        "\n",
        "[/PMLDL]\n",
        "''' \n",
        "\n",
        "# model = Classifier(1, 256, trainset.num_classes)\n",
        "# model = Classifier(1, 256, trainset.num_classes)\n",
        "model = Classifier(50, 256, trainset.num_classes)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "model.train()\n",
        "\n",
        "epoch_losses = []\n",
        "for epoch in range(80):\n",
        "    epoch_loss = 0\n",
        "    for iter, (bg, features, label) in enumerate(data_loader):\n",
        "        # print(iter)\n",
        "        prediction = model(bg, features)\n",
        "        loss = loss_func(prediction, label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.detach().item()\n",
        "        # print('Epoch {}, loss {:.4f}'.format(iter, epoch_loss))\n",
        "    epoch_loss /= (iter + 1)\n",
        "    print('Epoch {}, loss {:.4f}'.format(epoch, epoch_loss))\n",
        "    epoch_losses.append(epoch_loss)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss 2.5636\n",
            "Epoch 1, loss 2.0684\n",
            "Epoch 2, loss 1.9937\n",
            "Epoch 3, loss 1.8868\n",
            "Epoch 4, loss 1.8025\n",
            "Epoch 5, loss 1.8171\n",
            "Epoch 6, loss 1.9123\n",
            "Epoch 7, loss 1.7805\n",
            "Epoch 8, loss 1.7166\n",
            "Epoch 9, loss 1.6958\n",
            "Epoch 10, loss 1.6968\n",
            "Epoch 11, loss 1.6946\n",
            "Epoch 12, loss 1.6038\n",
            "Epoch 13, loss 1.6266\n",
            "Epoch 14, loss 1.7650\n",
            "Epoch 15, loss 1.6501\n",
            "Epoch 16, loss 1.5981\n",
            "Epoch 17, loss 1.6174\n",
            "Epoch 18, loss 1.5785\n",
            "Epoch 19, loss 1.5537\n",
            "Epoch 20, loss 1.5776\n",
            "Epoch 21, loss 1.4827\n",
            "Epoch 22, loss 1.5250\n",
            "Epoch 23, loss 1.5682\n",
            "Epoch 24, loss 1.4929\n",
            "Epoch 25, loss 1.4253\n",
            "Epoch 26, loss 1.5012\n",
            "Epoch 27, loss 1.5129\n",
            "Epoch 28, loss 1.4968\n",
            "Epoch 29, loss 1.4650\n",
            "Epoch 30, loss 1.4796\n",
            "Epoch 31, loss 1.4907\n",
            "Epoch 32, loss 1.4417\n",
            "Epoch 33, loss 1.4887\n",
            "Epoch 34, loss 1.4710\n",
            "Epoch 35, loss 1.5447\n",
            "Epoch 36, loss 1.4465\n",
            "Epoch 37, loss 1.4268\n",
            "Epoch 38, loss 1.4153\n",
            "Epoch 39, loss 1.5202\n",
            "Epoch 40, loss 1.5098\n",
            "Epoch 41, loss 1.4519\n",
            "Epoch 42, loss 1.4201\n",
            "Epoch 43, loss 1.3994\n",
            "Epoch 44, loss 1.3619\n",
            "Epoch 45, loss 1.4629\n",
            "Epoch 46, loss 1.4043\n",
            "Epoch 47, loss 1.4282\n",
            "Epoch 48, loss 1.4661\n",
            "Epoch 49, loss 1.3471\n",
            "Epoch 50, loss 1.3884\n",
            "Epoch 51, loss 1.4016\n",
            "Epoch 52, loss 1.4274\n",
            "Epoch 53, loss 1.4038\n",
            "Epoch 54, loss 1.4496\n",
            "Epoch 55, loss 1.3202\n",
            "Epoch 56, loss 1.3929\n",
            "Epoch 57, loss 1.3958\n",
            "Epoch 58, loss 1.4613\n",
            "Epoch 59, loss 1.4907\n",
            "Epoch 60, loss 1.3868\n",
            "Epoch 61, loss 1.4284\n",
            "Epoch 62, loss 1.3789\n",
            "Epoch 63, loss 1.2928\n",
            "Epoch 64, loss 1.2930\n",
            "Epoch 65, loss 1.3862\n",
            "Epoch 66, loss 1.3581\n",
            "Epoch 67, loss 1.2985\n",
            "Epoch 68, loss 1.2571\n",
            "Epoch 69, loss 1.2762\n",
            "Epoch 70, loss 1.3205\n",
            "Epoch 71, loss 1.3457\n",
            "Epoch 72, loss 1.3791\n",
            "Epoch 73, loss 1.2876\n",
            "Epoch 74, loss 1.3786\n",
            "Epoch 75, loss 1.2873\n",
            "Epoch 76, loss 1.2667\n",
            "Epoch 77, loss 1.2818\n",
            "Epoch 78, loss 1.2803\n",
            "Epoch 79, loss 1.2917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDF0Fp21_Dzh"
      },
      "source": [
        "The learning curve of a run is presented below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9kHyaax_Dzi",
        "outputId": "7bc0476c-1a58-4ec1-b3af-7db0c6892e4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.title('cross entropy averaged over minibatches')\n",
        "plt.plot(epoch_losses)\n",
        "plt.show()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX7jEnlJ_Dzi"
      },
      "source": [
        "The trained model is evaluated on the test set created. To deploy\n",
        "the tutorial, restrict the running time to get a higher\n",
        "accuracy ($80$ % ~ $90$ %) than the ones printed below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFVLC9pL_Dzi",
        "outputId": "a71822ae-5988-4e35-b9da-a39d724d215d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.eval()\n",
        "# Convert a list of tuples to two lists\n",
        "'''\n",
        "[PMLDL]\n",
        "\n",
        "Slightly modify this code to evaluate results, as batch should contain three elements\n",
        "\n",
        "[/PMLDL]\n",
        "''' \n",
        "test_X, test_F, test_Y = map(list, zip(*testset))\n",
        "test_bg = dgl.batch(test_X)\n",
        "test_Y = torch.tensor(test_Y).float().view(-1, 1)\n",
        "test_F = torch.cat(test_F, dim=0)\n",
        "probs_Y = torch.softmax(model(test_bg, test_F), 1)\n",
        "sampled_Y = torch.multinomial(probs_Y, 1)\n",
        "argmax_Y = torch.max(probs_Y, 1)[1].view(-1, 1)\n",
        "print('Accuracy of sampled predictions on the test set: {:.4f}%'.format(\n",
        "    (test_Y == sampled_Y.float()).sum().item() / len(test_Y) * 100))\n",
        "print('Accuracy of argmax predictions on the test set: {:4f}%'.format(\n",
        "    (test_Y == argmax_Y.float()).sum().item() / len(test_Y) * 100))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of sampled predictions on the test set: 35.0000%\n",
            "Accuracy of argmax predictions on the test set: 50.000000%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZVi9MUj_Dzj"
      },
      "source": [
        "\n",
        "\n",
        "What's next?\n",
        "------------\n",
        "Graph classification with graph neural networks is still a new field.\n",
        "It's waiting for people to bring more exciting discoveries. The work requires \n",
        "mapping different graphs to different embeddings, while preserving\n",
        "their structural similarity in the embedding space. To learn more about it, see \n",
        "`How Powerful Are Graph Neural Networks? <https://arxiv.org/abs/1810.00826>`_ a research paper  \n",
        "published for the International Conference on Learning Representations 2019.\n",
        "\n",
        "For more examples about batched graph processing, see the following:\n",
        "\n",
        "* Tutorials for `Tree LSTM <https://docs.dgl.ai/tutorials/models/2_small_graph/3_tree-lstm.html>`_ and `Deep Generative Models of Graphs <https://docs.dgl.ai/tutorials/models/3_generative_model/5_dgmg.html>`_\n",
        "* An example implementation of `Junction Tree VAE <https://github.com/dmlc/dgl/tree/master/examples/pytorch/jtnn>`_\n",
        "\n"
      ]
    }
  ]
}